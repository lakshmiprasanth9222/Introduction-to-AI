# -*- coding: utf-8 -*-
"""NLP assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14lVOtWDBEAsq_18hVk99qXMUBOgDktog
"""

# Basic data handling
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Classical NLP
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from nltk import pos_tag

# Transformers and deep learning
!pip install -q transformers
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# PyTorch (for transformers)
import torch
from torch.utils.data import Dataset, DataLoader

# Download NLTK assets
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')

# Load the dataset
df = pd.read_csv('/content/spam.csv', encoding='ISO-8859-1')

# Display the first few rows
df.head()

# Check the column names and data types
print(df.columns)

# Check for null values
print(df.isnull().sum())

# Keep only the first two columns and rename them
df = df[['v1', 'v2']]
df.columns = ['label', 'text']

# Encode label: ham = 0, spam = 1
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

# Drop any rows with missing text (just in case)
df.dropna(inplace=True)

# Check the result
print(df.head())

# Class distribution
print("\nClass distribution:")
print(df['label'].value_counts())

"""Classical NLP Preprocessing"""

import nltk
nltk.download('punkt')

from nltk.tokenize import TreebankWordTokenizer

tokenizer = TreebankWordTokenizer()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = tokenizer.tokenize(text)
    processed = [stemmer.stem(word) for word in tokens if word not in stop_words]
    return ' '.join(processed)

# Apply the fixed preprocessing
df['processed_text'] = df['text'].apply(preprocess_text)

# Show sample
df[['text', 'processed_text']].head()

"""Training the Classical NLP Model (Logistic Regression)"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Vectorize processed text
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['processed_text'])
y = df['label']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

!pip install -q transformers

from transformers import BertTokenizer, BertForSequenceClassification
from torch.utils.data import Dataset, DataLoader
import torch

# Load the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize the texts
tokens = tokenizer(
    list(df['text']),  # raw text, not processed_text
    max_length=128,
    padding='max_length',
    truncation=True,
    return_tensors='pt'
)

# Prepare labels
labels = torch.tensor(df['label'].values)

# Custom Dataset class
class SpamDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = self.labels[idx]
        return item

# Create dataset
dataset = SpamDataset(tokens, labels)

from sklearn.model_selection import train_test_split

# Split inputs and labels
train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)

# Use Subset to split
from torch.utils.data import Subset

train_dataset = Subset(dataset, train_idx)
val_dataset = Subset(dataset, val_idx)

from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification

# Load tokenizer and model
tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

# Re-tokenize using DistilBERT tokenizer
tokens = tokenizer(
    list(df['text']),
    max_length=128,
    padding='max_length',
    truncation=True,
    return_tensors='pt'
)

# Prepare labels again
labels = torch.tensor(df['label'].values)

# Reuse SpamDataset class
class SpamDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = self.labels[idx]
        return item

# Create dataset
dataset = SpamDataset(tokens, labels)

from sklearn.model_selection import train_test_split
from torch.utils.data import Subset

# Create train/val indices
train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)

# Create subsets
train_dataset = Subset(dataset, train_idx)
val_dataset = Subset(dataset, val_idx)

from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained(
    'distilbert-base-uncased',
    num_labels=2
)

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=1,
    per_device_train_batch_size=10,
    per_device_eval_batch_size=20,
    logging_dir='./logs',
    logging_steps=5
)

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

# Run evaluation
eval_results = trainer.evaluate()

# Show evaluation metrics
print("Evaluation results:")
for key, value in eval_results.items():
    print(f"{key}: {value}")

import matplotlib.pyplot as plt
import numpy as np

# Model names
models = ['Logistic Regression', 'DistilBERT']

# Performance metrics from both models
accuracy = [0.9489, 0.9937]
precision = [0.96, 0.9864]
recall = [0.65, 0.9667]
f1 = [0.77, 0.9764]

# Set bar width and positions
bar_width = 0.2
x = np.arange(len(models))

# Plot each metric
plt.figure(figsize=(10, 6))
plt.bar(x - 1.5 * bar_width, accuracy, width=bar_width, label='Accuracy')
plt.bar(x - 0.5 * bar_width, precision, width=bar_width, label='Precision')
plt.bar(x + 0.5 * bar_width, recall, width=bar_width, label='Recall')
plt.bar(x + 1.5 * bar_width, f1, width=bar_width, label='F1 Score')

# Labeling and layout
plt.xticks(x, models)
plt.ylim(0, 1.1)
plt.ylabel("Score")
plt.title("Model Performance Comparison: Classical vs Transformer")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()

# Show the plot
plt.show()

"""Getting Misclassified Examples (False Positives / Negatives)"""

# Make predictions
predictions = trainer.predict(val_dataset)
preds = np.argmax(predictions.predictions, axis=1)
true_labels = predictions.label_ids

# Find false positives and false negatives
false_positives = np.where((preds == 1) & (true_labels == 0))[0]
false_negatives = np.where((preds == 0) & (true_labels == 1))[0]

# Print a few false positives
print("\nFalse Positives (Ham misclassified as Spam):")
for idx in false_positives[:3]:
    print(df.iloc[val_idx[idx]]['text'])

# Print a few false negatives
print("\nFalse Negatives (Spam misclassified as Ham):")
for idx in false_negatives[:3]:
    print(df.iloc[val_idx[idx]]['text'])

!pip install numpy==1.24.4 --force-reinstall

from nltk.tokenize import TreebankWordTokenizer

# Use Treebank tokenizer instead of word_tokenize()
tokenizer = TreebankWordTokenizer()

# Updated cleaning function
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = tokenizer.tokenize(text)
    return tokens

# Recreate corpus
corpus = df['text'].apply(clean_text).tolist()
print("Sample:", corpus[0])

from gensim.models import Word2Vec

# Train CBOW model (sg=0)
cbow_model = Word2Vec(
    sentences=corpus,
    vector_size=100,
    window=5,
    min_count=2,
    sg=0,  # CBOW
    epochs=20
)

# Train Skip-gram model (sg=1)
skipgram_model = Word2Vec(
    sentences=corpus,
    vector_size=100,
    window=5,
    min_count=2,
    sg=1,  # Skip-gram
    epochs=20
)

print("CBOW and Skip-gram models trained successfully.")

# Words to test (must exist in your corpus)
target_words = ['free', 'win', 'call', 'urgent']

# Check most similar words using CBOW
print(" CBOW model - Most similar words:")
for word in target_words:
    if word in cbow_model.wv:
        print(f"\n{word} →", cbow_model.wv.most_similar(word, topn=5))
    else:
        print(f"\n'{word}' not in vocabulary.")

# Check most similar words using Skip-gram
print("\nSkip-gram model - Most similar words:")
for word in target_words:
    if word in skipgram_model.wv:
        print(f"\n{word} →", skipgram_model.wv.most_similar(word, topn=5))
    else:
        print(f"\n'{word}' not in vocabulary.")

# Analogy: win - prize + cash ≈ ?
try:
    result = cbow_model.wv.most_similar(positive=['win', 'cash'], negative=['prize'])
    print("\n CBOW Analogy Test: win - prize + cash =", result[0])
except:
    print("\nAnalogy words not in vocabulary.")

import nltk
nltk.download('stopwords')

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import TreebankWordTokenizer

# Re-initialize tools
tokenizer = TreebankWordTokenizer()
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = tokenizer.tokenize(text)
    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# Apply preprocessing
df['processed_text'] = df['text'].apply(preprocess_text)

# Check
df[['text', 'processed_text']].head()

# 1. TF-IDF Vectorization
from sklearn.feature_extraction.text import TfidfVectorizer
X = df['processed_text']  # From Task 2
y = df['label']

vectorizer = TfidfVectorizer()
X_vec = vectorizer.fit_transform(X)

# 2. Train/test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)

# 3. Train baseline classifier
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)

# 4. Predict and evaluate
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# Evaluation metrics
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_prob))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Ham", "Spam"])
disp.plot(cmap='Blues')